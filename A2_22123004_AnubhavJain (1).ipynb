{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9281d17d",
   "metadata": {},
   "source": [
    "# ASSIGNMENT-2 , ANUBHAV JAIN(22123004)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "472584ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING LIBRARIES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae391c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING CRACKED DATA\n",
    "data_1=os.listdir('C:\\\\Users\\\\ANUBHAV\\\\Desktop\\\\ASSIGNMENT_DATA\\\\train\\\\cracked')   \n",
    "#IMPORTING UNCRACKED DATA\n",
    "data_2=os.listdir('C:\\\\Users\\\\ANUBHAV\\\\Desktop\\\\ASSIGNMENT_DATA\\\\train\\\\uncracked') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cd71f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONVERTING THE IMAGE DATA OF CRACKRD AND UNCRACKED FILES INTO 50*50 PIXEL SIZE IN GREYSCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f7df3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Set the source directory for the images and the output CSV file path\n",
    "source_dir = 'C:\\\\Users\\\\ANUBHAV\\\\Desktop\\\\ASSIGNMENT_DATA\\\\train\\\\uncracked'\n",
    "output_path = 'C:\\\\Users\\\\ANUBHAV\\\\Desktop\\\\ASSIGNMENT_DATA\\\\anubhav\\\\uncraracked.csv'\n",
    "\n",
    "\n",
    "data = []\n",
    "\n",
    "# Loop over the image files in the directory\n",
    "for file_name in os.listdir(source_dir):\n",
    "    # Open the image and resize it to 50*50 pixels\n",
    "    image = Image.open(os.path.join(source_dir, file_name)).convert('L')\n",
    "\n",
    "    # Convert  to grayscale\n",
    "    gray_image = image.resize((50,50))\n",
    "\n",
    "\n",
    "    # Convert the image to a numpy array and flatten it to a 1D array\n",
    "    pixels = np.array(gray_image).flatten()\n",
    "    # Add the flattened array to the list\n",
    "    data.append(pixels)\n",
    "\n",
    "# Create a pandas dataframe \n",
    "df = pd.DataFrame(data)\n",
    "df.insert(0,'label','uncracked')\n",
    "\n",
    "# Save  to a CSV file\n",
    "df.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45007e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Set the source directory for the images and the output CSV file path\n",
    "source_dir = 'C:\\\\Users\\\\ANUBHAV\\\\Desktop\\\\ASSIGNMENT_DATA\\\\train\\\\cracked'\n",
    "output_path = 'C:\\\\Users\\\\ANUBHAV\\\\Desktop\\\\ASSIGNMENT_DATA\\\\anubhav\\\\cracked.csv'\n",
    "\n",
    "ata = []\n",
    "\n",
    "# Loop over the image files in the directory\n",
    "for file_name in os.listdir(source_dir):\n",
    "#      resize it to 50*50 pixels\n",
    "    image = Image.open(os.path.join(source_dir, file_name)).convert('L')\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray_image = image.resize((50,50))\n",
    "\n",
    "\n",
    "    # Convert the image to a numpy array and flatten it to a 1D array\n",
    "    pixels = np.array(gray_image).flatten()\n",
    "    # Add the flattened array to the list\n",
    "    data.append(pixels)\n",
    "\n",
    "# Create a pandas dataframe from the list of pixel values\n",
    "df = pd.DataFrame(data)\n",
    "df.insert(0,'label','cracked')\n",
    "\n",
    "# Save the dataframe to a CSV file\n",
    "df.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "233645d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load the two CSV files into separate Pandas dataframes\n",
    "df1 = pd.read_csv(\"C:\\\\Users\\\\ANUBHAV\\\\Desktop\\\\ASSIGNMENT_DATA\\\\anubhav\\\\cracked.csv\") \n",
    "df2 = pd.read_csv(\"C:\\\\Users\\\\ANUBHAV\\\\Desktop\\\\ASSIGNMENT_DATA\\\\anubhav\\\\uncraracked.csv\") \n",
    "# TWO csv FILES ARE CREATED , ER HAVE TO MERGE THEM RANDOMLY AND MAKE ONE SINGLE FILE \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "566eb119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "merged_df = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "\n",
    "merged_df.to_csv(\"C:\\\\Users\\\\ANUBHAV\\\\Desktop\\\\ASSIGNMENT_DATA\\\\anubhav\\\\merged_file.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fa09307",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Shuffle the rows of the merged dataframe using np.random.permutation method:\n",
    "shuffled_df = merged_df.reindex(np.random.permutation(merged_df.index))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75512102",
   "metadata": {},
   "source": [
    "# IMPORTING LIBRARIES FOR VGG16  MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "380949bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f28c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  randomly mixing the 2 CSV files\n",
    "dfg = pd.read_csv(\"C:\\\\Users\\\\ANUBHAV\\\\Desktop\\\\ASSIGNMENT_DATA\\\\anubhav\\\\merged_file.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fc1f5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dfg['label']\n",
    "X=dfg.drop(['label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e86c6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfg.drop('label', axis=1).values.reshape(-1, 50,50, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36dbb51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\PYTHON 3.10\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:808: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "#  y contains categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_onehot = onehot_encoder.fit_transform(y_encoded.reshape(-1, 1))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46fb3913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05444723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "y_test = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bbbed49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\PYTHON 3.10\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:808: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 90s 238ms/step - loss: 0.7478 - accuracy: 0.6749 - val_loss: 0.5826 - val_accuracy: 0.7108\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 94s 251ms/step - loss: 0.5261 - accuracy: 0.7238 - val_loss: 0.5865 - val_accuracy: 0.7114\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 95s 253ms/step - loss: 0.5034 - accuracy: 0.7348 - val_loss: 0.5655 - val_accuracy: 0.7198\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 94s 251ms/step - loss: 0.4770 - accuracy: 0.7576 - val_loss: 0.5650 - val_accuracy: 0.7208\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 96s 255ms/step - loss: 0.4617 - accuracy: 0.7627 - val_loss: 0.5890 - val_accuracy: 0.7214\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 94s 250ms/step - loss: 0.4448 - accuracy: 0.7726 - val_loss: 0.6025 - val_accuracy: 0.7178\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 97s 260ms/step - loss: 0.4377 - accuracy: 0.7811 - val_loss: 0.6248 - val_accuracy: 0.7211\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 93s 249ms/step - loss: 0.4266 - accuracy: 0.7876 - val_loss: 0.6628 - val_accuracy: 0.7111\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 94s 250ms/step - loss: 0.4182 - accuracy: 0.7889 - val_loss: 0.6559 - val_accuracy: 0.7211\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 94s 250ms/step - loss: 0.4063 - accuracy: 0.7964 - val_loss: 0.6958 - val_accuracy: 0.7181\n",
      "94/94 [==============================] - 18s 194ms/step - loss: 0.6958 - accuracy: 0.7181\n",
      "Test loss: 0.6957976222038269\n",
      "Test accuracy: 0.7181028723716736\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Load data from CSV file\n",
    "data = pd.read_csv('C:\\\\Users\\\\ANUBHAV\\\\Desktop\\\\ASSIGNMENT_DATA\\\\anubhav\\\\merged_file.csv')\n",
    "X_gray = data.iloc[:, 1:].values.reshape(-1, 50,50, 1).astype('float32') # reshape to (n_samples, height, width, channels)\n",
    "X = np.concatenate([X_gray]*3, axis=-1) # duplicate grayscale channel to create pseudo-RGB images\n",
    "y = data.iloc[:, 0].values\n",
    "\n",
    "# Convert string labels to numeric labels using label encoding\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Convert numeric labels to one-hot encoding\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "y = ohe.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Load pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(50,50, 3))\n",
    "\n",
    "# Add custom top layers for grayscale image classification\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(len(le.classes_), activation='softmax')(x)\n",
    "\n",
    "# Create a new model with custom top layers\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate model on test set\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4e1cbe",
   "metadata": {},
   "source": [
    "# Test loss: 0.6957976222038269    ,  Test accuracy: 0.7181028723716736\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8698d295",
   "metadata": {},
   "source": [
    "# calculataing F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0c58d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 35s 369ms/step\n",
      "F1 score: 0.7459576926232551\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Predict labels for test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print('F1 score:', f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee4144b",
   "metadata": {},
   "source": [
    "# F1 score: 0.745\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b2056b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearing the session frees up resources and ensures that the next training or testing session starts with a clean state.\n",
    "from keras import backend as K\n",
    "K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89a453bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2320"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "# gc stands for Garbage Collector, which is a mechanism in Python that automatically frees up memory that is no longer \n",
    "# being used by the program.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e5a3c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  saving our VGG model \n",
    "model.save('vgg_model.h16')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a567e501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('vgg_model.h16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e1a421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets convert the prediction images into the grey scale\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    " \n",
    "# Set the source directory for the images and the output CSV file path\n",
    "source_dir = 'C:\\\\Users\\\\ANUBHAV\\\\Desktop\\\\ASSIGNMENT_DATA\\\\test'\n",
    "output_path = 'C:\\\\Users\\\\ANUBHAV\\\\Desktop\\\\ASSIGNMENT_DATA\\\\anubhav\\\\test_data.csv'\n",
    "\n",
    "# Initialize an empty list to store the flattened pixel values\n",
    "data = []\n",
    "   \n",
    "# Loop over the image files in the directory\n",
    "for file_name in os.listdir(source_dir):\n",
    "    # Open the image and resize it to 50*50 pixels\n",
    "    image = Image.open(os.path.join(source_dir, file_name)).convert('L')\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = image.resize((50,50))\n",
    "\n",
    "\n",
    "    # Convert the image to a numpy array and flatten it to a 1D array\n",
    "    pixels = np.array(gray_image).flatten()\n",
    "    # Add the flattened array to the list\n",
    "    data.append(pixels)\n",
    "\n",
    "# Create a pandas dataframe from the list of pixel values\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Save the dataframe to a CSV file\n",
    "df.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de0596b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('vgg_model.h16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3fb50b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data from CSV file\n",
    "data = pd.read_csv('C:\\\\Users\\\\ANUBHAV\\\\Desktop\\\\ASSIGNMENT_DATA\\\\anubhav\\\\test_data.csv')\n",
    "X_gray = data.iloc[:,0:].values.reshape(-1,50,50,1)# reshape to (n_samples, height, width, channels)\n",
    "X = np.concatenate([X_gray]*3, axis=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10fcc8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set the source directory for the images and the output CSV file path\n",
    "source_dir = 'C:\\\\Users\\\\ANUBHAV\\\\Desktop\\\\ASSIGNMENT_DATA\\\\test'\n",
    "output_path = 'C:\\\\Users\\\\ANUBHAV\\\\Desktop\\\\ASSIGNMENT_DATA\\\\anubhav\\\\testing_new'\n",
    "\n",
    "# Initialize an empty list to store the flattened pixel values\n",
    "data = []\n",
    "\n",
    "# Loop over the image files in the directory\n",
    "for i in range(1, 2001):\n",
    "    # Open the image and resize it to 50,50 pixels\n",
    "    file_name = f'{i}.jpg'\n",
    "    image = Image.open(os.path.join(source_dir, file_name)).convert('L')\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = image.resize((50,50))\n",
    "\n",
    "    # Convert the image to a numpy array and flatten it to a 1D array\n",
    "    pixels = np.array(gray_image).flatten()\n",
    "    # Add the flattened array to the list\n",
    "    data.append(pixels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "973078b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas dataframe from the list of pixel values\n",
    "df = pd.DataFrame(data)\n",
    "df.insert(0,'Image',['{}.jpg'.format(i) for i in range(1,2001)])\n",
    "\n",
    "# Load the model\n",
    "model = load_model('vgg_model.h16')\n",
    "\n",
    "# Reshape the data for input to the model\n",
    "X_gray = df.iloc[:,1:].values.reshape(-1,50,50,1)\n",
    "X = np.concatenate([X_gray]*3, axis=-1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fb401ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 10s 153ms/step\n"
     ]
    }
   ],
   "source": [
    "# Making final  predictions on the test data\n",
    "predictions = model.predict(X)\n",
    "labels = ['Cracked' if prediction[0] > prediction[1] else 'Uncracked' for prediction in predictions]\n",
    "\n",
    "# Create a Pandas DataFrame with the predictions\n",
    "df = pd.DataFrame({'Image': df['Image'], 'class': labels})\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "df.to_csv('C:\\\\Users\\\\ANUBHAV\\\\Desktop\\\\ASSIGNMENT_DATA\\\\anubhav\\\\my_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83d22540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_predictions.csv file contains prediction made by our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f356950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "dk = pd.read_csv('C:\\\\Users\\\\ANUBHAV\\\\Desktop\\\\ASSIGNMENT_DATA\\\\anubhav\\\\my_predictions.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adf8c170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the counts of values in the desired column\n",
    "counts = dk['class'].value_counts()\n",
    "\n",
    "# Create a pie chart with the counts\n",
    "plt.pie(counts.values, labels=counts.index, wedgeprops={'linewidth': 3, 'edgecolor': 'white'})\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa6e7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
